{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf511e6b-8b91-4b99-aeec-fd460c5fd68f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.63.3\n"
     ]
    }
   ],
   "source": [
    "!oci --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc9c515-7202-4941-beb5-890fc0671ddb",
   "metadata": {},
   "source": [
    "## Configuración de la autenticación del SDK de OCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83589cee-e292-4ab2-9646-1a487ee577bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea carpeta y permisos\n",
    "!mkdir -p /home/datascience/.oci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615111c8-27f5-434b-adb9-6a8a269ca85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver tu HOME y listar (incluye ocultos)\n",
    "!echo $HOME\n",
    "!ls -la $HOME | head -n 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb5437f8-6732-46d2-8c3a-6d0eac858251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16\n",
      "drwxr-xr-x.  2 datascience users 4096 Sep  8 05:22 .\n",
      "drwxr-xr-x. 13 datascience users 4096 Sep  8 07:18 ..\n",
      "-rw-r--r--.  1 datascience users  308 Sep  8 05:22 config\n",
      "-rw-------.  1 datascience users 1715 Sep  8 02:38 oci_api_key.pem\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/.oci\n",
    "!ls -la ~/.oci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae296113-bb25-46ae-b6ec-2013e2bee3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > ~/.oci/config <<'CFG'\n",
    "[DEFAULT]\n",
    "user=ocid1.user.oc1..aa...\n",
    "tenancy=ocid1.tenancy.oc1..aaa...\n",
    "region=us-chicago-1\n",
    "fingerprint=f6:ec:66:50...\n",
    "key_file=/home/datascience/.oci/oci_api_key.pem\n",
    "CFG\n",
    "\n",
    "echo \"Config creado en ~/.oci/config\"\n",
    "cat ~/.oci/config | sed 's/fingerprint=.*/fingerprint=<oculto>/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c1907f-c429-496a-b28d-fa00802f7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quita posibles finales de línea de Windows (CRLF)\n",
    "!sed -i 's/\\r$//' ~/.oci/config\n",
    "\n",
    "# mostrar\n",
    "!sed -n '1,200p' ~/.oci/config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b745e4a-0c5d-4db5-8ab8-8b020e3d2b38",
   "metadata": {},
   "source": [
    "# Usando los Modelos de LLM usando Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a503bec-6da6-4523-9426-0d88c2c4851c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_input = \"qué es llama?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90590031-1848-487a-b751-74859289a529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"response\": \"\\\"Llama\\\" puede tener diferentes significados dependiendo del contexto. Aquí te explico los más comunes:\\n\\n1. **Animal**: La llama es un mamífero camélido originario de Sudamérica, especialmente de los Andes (Perú, Bolivia, Chile, Argentina). Es un animal doméstico utilizado principalmente como animal de carga y por su lana. Es pariente de la alpaca, el guanaco y la vicuña. Las llamas son conocidas por su temperamento tranquilo, aunque pueden escupir si se sienten amenazadas o molestas.\\n\\n2. **Fuego o flama**: En español, \\\"llama\\\" también significa \\\"flama\\\" o la parte visible del fuego. Por ejemplo: \\\"La llama de la vela es muy brillante\\\".\\n\\n3. **Llamada telefónica (en algunos países)**: En ciertos países de habla hispana, como México, \\\"llama\\\" puede ser una forma coloquial de referirse a una llamada telefónica. Por ejemplo: \\\"¿Me haces una llama cuando llegues?\\\"\\n\\n4. **Llama como verbo**: Es la tercera persona del singular del verbo \\\"llamar\\\" en presente. Por ejemplo: \\\"Él llama a su amigo todos los días\\\".\\n\\n5. **LLaMA (en tecnología)**: Si te refieres a algo relacionado con tecnología, LLaMA es el nombre de un modelo de inteligencia artificial desarrollado por Meta (la empresa detrás de Facebook). Significa \\\"Large Language Model Meta AI\\\" y se utiliza para tareas de procesamiento de lenguaje natural.\\n\\nSi tienes un contexto más específico, puedo profundizar en alguno de estos significados. ¿A qué te refieres exactamente?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import oci\n",
    "import json\n",
    "from oci.auth.signers import get_resource_principals_signer\n",
    "\n",
    "# === Config ===\n",
    "REGION = \"us-chicago-1\"\n",
    "SERVICE_ENDPOINT = f\"https://inference.generativeai.{REGION}.oci.oraclecloud.com\"\n",
    "COMPARTMENT_ID = \"ocid1.compartment.oc1..aaaaaaaawy5gpq67r3rxc7yf6yn7oesvvgr56dqg7o5y3f5ndzt2mddtj46a\"\n",
    "MODEL_ID = \"ocid1.generativeaimodel.oc1.us-chicago-1.amaaaaaask7dceya6dvgvvj3ovy4lerdl6fvx525x3yweacnrgn4ryfwwcoq\"\n",
    "\n",
    "# === Signer===\n",
    "signer = get_resource_principals_signer()\n",
    "cfg = {\"region\": REGION}\n",
    "\n",
    "# (opcional)\n",
    "if MODEL_ID is None:\n",
    "    from oci.generative_ai import GenerativeAiClient\n",
    "    genai = GenerativeAiClient(config=cfg, signer=signer)\n",
    "    models = genai.list_models(\n",
    "        compartment_id=COMPARTMENT_ID,\n",
    "        capability=[\"CHAT\"],\n",
    "        lifecycle_state=\"ACTIVE\"\n",
    "    ).data.items\n",
    "    assert models, \"No hay modelos CHAT visibles en el compartimento. Revisa permisos/compartimento.\"\n",
    "    MODEL_ID = models[0].id\n",
    "    print(\"Usando modelo:\", MODEL_ID)\n",
    "\n",
    "# === Cliente de inferencia ===\n",
    "inf = oci.generative_ai_inference.GenerativeAiInferenceClient(\n",
    "    config=cfg, signer=signer, service_endpoint=SERVICE_ENDPOINT\n",
    ")\n",
    "\n",
    "# === Prompt del usuario ===\n",
    "user_input = user_input\n",
    "\n",
    "# --- Construcción del request ---\n",
    "content = oci.generative_ai_inference.models.TextContent(text=user_input)\n",
    "message = oci.generative_ai_inference.models.Message(role=\"USER\", content=[content])\n",
    "\n",
    "chat_request = oci.generative_ai_inference.models.GenericChatRequest(\n",
    "    api_format=oci.generative_ai_inference.models.BaseChatRequest.API_FORMAT_GENERIC,\n",
    "    messages=[message],\n",
    "    max_tokens=600,\n",
    "    temperature=1.0,\n",
    "    frequency_penalty=0.0,\n",
    "    presence_penalty=0.0,\n",
    "    top_p=0.75,\n",
    ")\n",
    "\n",
    "chat_detail = oci.generative_ai_inference.models.ChatDetails(\n",
    "    serving_mode=oci.generative_ai_inference.models.OnDemandServingMode(model_id=MODEL_ID),\n",
    "    chat_request=chat_request,\n",
    "    compartment_id=COMPARTMENT_ID,\n",
    ")\n",
    "\n",
    "# === Llamada ===\n",
    "resp = inf.chat(chat_detail)\n",
    "\n",
    "# === Resultado ===\n",
    "choices = resp.data.chat_response.choices\n",
    "response_text = choices[0].message.content[0].text if choices else \"No se generó respuesta.\"\n",
    "print(json.dumps({\"response\": response_text}, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ec1c7-a765-4dc9-99bb-b958d9b314ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
