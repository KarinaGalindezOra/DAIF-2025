{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7bf3f0c-d028-482e-9422-d6a824d48cb0",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1976a2ce-dccb-49fe-b74c-9aca2cd1e1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESPUESTA ===\n",
      " La imagen muestra a una mujer tomando una selfie con una llama en un entorno al aire libre. La mujer, con el pelo oscuro y rizado y gafas negras, sonríe y mira directamente a la cámara. Lleva una chaqueta rosa sobre una camiseta azul oscura. La llama, con un abrigo blanco y manchas marrones, se para a su derecha, mirando hacia la cámara con las orejas hacia arriba. En el fondo, un camino de tierra conduce a una valla de madera, con árboles y una casa visible a lo lejos. La atmósfera general sugiere un día soleado en un zoológico o santuario de vida silvestre.\n"
     ]
    }
   ],
   "source": [
    "# --- Multimodal chat (imagen + texto) en OCI Generative AI---\n",
    "\n",
    "import os, json, base64, mimetypes\n",
    "import oci\n",
    "\n",
    "# === Configuración base ===\n",
    "CONFIG_PROFILE = \"DEFAULT\"\n",
    "config = oci.config.from_file(os.path.expanduser(\"~/.oci/config\"), CONFIG_PROFILE)\n",
    "config[\"region\"] = \"us-chicago-1\"\n",
    "\n",
    "COMPARTMENT_ID = \"ocid1.compartment.oc1..aaaaaaaawy5gpq67r3rxc7yf6yn7oesvvgr56dqg7o5y3f5ndzt2mddtj46a\"\n",
    "ENDPOINT = \"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\"\n",
    "\n",
    "MODEL_ID = \"ocid1.generativeaimodel.oc1.us-chicago-1.amaaaaaask7dceyayjawvuonfkw2ua4bob4rlnnlhs522pafbglivtwlfzta\"\n",
    "assert \".oc1.us-chicago-1.\" in MODEL_ID, \"El model_id debe ser de la región us-chicago-1\"\n",
    "\n",
    "# === Utilidad: convertir imagen local a data URL base64 ===\n",
    "def image_to_data_url(path: str) -> str:\n",
    "    mime = mimetypes.guess_type(path)[0] or \"image/jpeg\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    return f\"data:{mime};base64,{b64}\"\n",
    "\n",
    "# Ruta de tu imagen local\n",
    "IMG_PATH = \"demo-image.jpeg\"\n",
    "PROMPT = \"Describe brevemente lo que ves en la imagen.\"\n",
    "\n",
    "# Prepara contenidos multimodales\n",
    "from oci.generative_ai_inference import GenerativeAiInferenceClient\n",
    "from oci.generative_ai_inference.models import (\n",
    "    ChatDetails,\n",
    "    OnDemandServingMode,\n",
    "    GenericChatRequest,\n",
    "    BaseChatRequest,\n",
    "    Message,\n",
    "    TextContent,\n",
    "    ImageContent,\n",
    "    ImageUrl,\n",
    ")\n",
    "\n",
    "# Imagen como data URL (también puedes usar una URL pública HTTPS)\n",
    "img_data_url = image_to_data_url(IMG_PATH)\n",
    "\n",
    "image_url = ImageUrl(url=img_data_url)\n",
    "image_content = ImageContent(image_url=image_url)\n",
    "\n",
    "text_content = TextContent(text=PROMPT)\n",
    "\n",
    "user_message = Message(role=\"USER\", content=[text_content, image_content])\n",
    "\n",
    "chat_request = GenericChatRequest(\n",
    "    api_format=BaseChatRequest.API_FORMAT_GENERIC,\n",
    "    messages=[user_message],\n",
    "    max_tokens=400,\n",
    "    temperature=0.4,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "chat_details = ChatDetails(\n",
    "    serving_mode=OnDemandServingMode(model_id=MODEL_ID),\n",
    "    chat_request=chat_request,\n",
    "    compartment_id=COMPARTMENT_ID,\n",
    ")\n",
    "\n",
    "client = GenerativeAiInferenceClient(config=config, service_endpoint=ENDPOINT)\n",
    "resp = client.chat(chat_details)\n",
    "\n",
    "# Extrae y muestra el texto de la respuesta\n",
    "choices = resp.data.chat_response.choices\n",
    "if choices:\n",
    "    parts = choices[0].message.content\n",
    "    texto = \"\\n\".join(getattr(p, \"text\", \"\") for p in parts if hasattr(p, \"text\"))\n",
    "    print(\"\\n=== RESPUESTA ===\\n\", texto.strip())\n",
    "else:\n",
    "    print(\"No se generó respuesta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8da198-c24d-4a21-a075-0c10b041a0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
